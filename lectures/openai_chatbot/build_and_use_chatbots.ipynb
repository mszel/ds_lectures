{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAP by IEM: Data Science in Use - Demo 3: Chatbot\n",
    "This notebooks creates a very basic chatbot that allows you to speak about books and articles (stored in txt and pdf files). Questions: marton.szel@lynxanalytics.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporary solution before packaging the project\n",
    "import sys\n",
    "if not sys.path[0].endswith('/ds_lectures'):\n",
    "    sys.path.insert(0, sys.path[0].split('/ds_lectures')[0] + '/ds_lectures')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# basic ETL libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# own functions\n",
    "from src.configloader import load_config\n",
    "from src.chatbot_apps import page_preprocessor, knowledge_base_maker, answer_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the configuration\n",
    "chatbot_configuration_path = './demo_openai_bot.yaml'\n",
    "chatbot_configuration = load_config(chatbot_configuration_path)\n",
    "\n",
    "# chatbot_configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building up the knowledge base\n",
    "Create a knowledge base that the chatbot can use as a base."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the files\n",
    "The first step is to create a converter that makes the basic cleaning on the files. **TODO**: You can develop it by adding more preprocessors, or start using langchain library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_preprocessor(chatbot_configuration, _verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create embeddings\n",
    "The second step is splitting the files, and vectorize them. Finally, a knowledge base can be made. **TODO**: You can add a summary from all page and copy it to the top of all lines for getting better retrieval results while using the bot. Also, you can use much better text splitters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_base_maker(chatbot_configuration, _verbose=False)\n",
    "\n",
    "_outpath = chatbot_configuration['kb_builder']['path_kb'] + 'knowledge_base.pickle'\n",
    "pdf_knowledge_base = pd.read_pickle(_outpath)\n",
    "pdf_knowledge_base.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_knowledge_base.n_tokens.plot(kind='hist', bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asking questions from the knowledge base, using Open AI\n",
    "Converting the question to a vector, and collect the top info from the knowledge base. After, ask chat GPT to answer the question using the context. **TODO**: You can make it better by: \n",
    " * handling question/answer history\n",
    " * adding better bot prompts\n",
    " * writing better functions for retrieving the right information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_question = \"How many parameters GPT-3 has?\"\n",
    "user_question = \"What is the attention layer?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_bot_answer = answer_question(user_question, chatbot_configuration, _verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(_bot_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F.I.N.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LynxScribe",
   "language": "python",
   "name": "lynxscribe"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
