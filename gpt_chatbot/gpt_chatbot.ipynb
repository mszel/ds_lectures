{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAP by IEM: Data Science in Use - Demo 3: Chatbot\n",
    "This notebooks creates a very basic chatbot that allows you to speak about books and articles (stored in HTM and pdf files). </br>**Author**: marton.szel@lynxanalytics.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import pandas as pd\n",
    "from src.preprocess_utils import page_preprocessor, knowledge_base_maker\n",
    "from src.gpt_utils import answer_question\n",
    "\n",
    "# setting up autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "_foldername = 'book_robot'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building up the knowledge base\n",
    "Create a knowledge base that the chatbot can use as a base."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the files\n",
    "The first step is to create a converter that makes the basic cleaning on the files. **TODO**: You can develop it by adding more preprocessors, or start using langchain library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_preprocessor(\n",
    "    path_in_folder=f'./data/01_raw/{_foldername}/', \n",
    "    path_out_folder=f'./data/02_preprocessed/{_foldername}/',\n",
    "    _encoding='utf-8', _verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create embeddings\n",
    "The second step is splitting the files, and vectorize them. Finally, a knowledge base can be made. **TODO**: You can add a summary from all page and copy it to the top of all lines for getting better retrieval results while using the bot. Also, you can use much better text splitters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_base_maker(\n",
    "    path_in_folder=f'./data/02_preprocessed/{_foldername}/', \n",
    "    path_out_folder=f'./data/03_knowledge_base/{_foldername}/',\n",
    "    _encoding='latin1', min_token_size=128, max_token_size=512, \n",
    "    model='openai', _sleeptime=0.1, _verbose=True)\n",
    "\n",
    "pdf_knowledge_base = pd.read_pickle(\n",
    "    f'./data/03_knowledge_base/{_foldername}/knowledge_base.pickle')\n",
    "\n",
    "pdf_knowledge_base.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_knowledge_base.n_tokens.plot(kind='hist', bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asking questions from the knowledge base, using Open AI\n",
    "Converting the question to a vector, and collect the top info from the knowledge base. After, ask chat GPT to answer the question using the context. **TODO**: You can make it better by: \n",
    " * handling question/answer history\n",
    " * adding better bot prompts\n",
    " * writing better functions for retrieving the right information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = \"How many parameters GPT-3 has?\"\n",
    "user_question = \"What is the attention layer?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_bot_answer = answer_question(\n",
    "    path_in_knowledge_base=f'./data/03_knowledge_base/{_foldername}/knowledge_base.pickle', \n",
    "    in_question=user_question, project_name=_foldername, model='gpt3.5', \n",
    "    max_context_len=1500, _verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(_bot_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F.I.N.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p39_lynxenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
